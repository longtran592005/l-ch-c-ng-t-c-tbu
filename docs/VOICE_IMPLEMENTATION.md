# üé§ Voice-Guided Schedule Form - T·ªïng k·∫øt Implementation

## üì¶ C√°c file ƒë√£ t·∫°o

### 1. **Core Service**
```
src/services/voiceAI.service.ts
```
- X·ª≠ l√Ω gi·ªçng n√≥i b·∫±ng AI/LLM
- System prompt chuy√™n nghi·ªáp
- Fallback processing rule-based
- Chu·∫©n h√≥a d·ªØ li·ªáu theo t·ª´ng lo·∫°i field

### 2. **UI Component**
```
src/components/schedule/VoiceGuidedScheduleForm.tsx
```
- Form v·ªõi h∆∞·ªõng d·∫´n tu·∫ßn t·ª± t·ª´ng tr∆∞·ªùng
- Speech Recognition (gi·ªçng n√≥i ‚Üí text)
- Text-to-Speech (h∆∞·ªõng d·∫´n b·∫±ng gi·ªçng n√≥i)
- Hi·ªáu ·ª©ng s√°ng l√™n, animation
- Qu·∫£n l√Ω state ph·ª©c t·∫°p

### 3. **Documentation**
```
docs/VOICE_GUIDED_FORM.md
```
- H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng chi ti·∫øt
- V√≠ d·ª• cho t·ª´ng tr∆∞·ªùng
- X·ª≠ l√Ω l·ªói
- T√≠ch h·ª£p LLM

### 4. **Demo Page**
```
src/pages/demo/VoiceGuidedFormDemo.tsx
```
- Trang demo ƒë·ªÉ test
- H∆∞·ªõng d·∫´n tr·ª±c quan
- Hi·ªÉn th·ªã k·∫øt qu·∫£

### 5. **Tailwind Config**
```
tailwind.config.ts
```
- Th√™m animation `pulse-slow`

## üöÄ C√°ch t√≠ch h·ª£p v√†o ScheduleManagement

### B∆∞·ªõc 1: Import component

```tsx
import { VoiceGuidedScheduleForm } from '@/components/schedule/VoiceGuidedScheduleForm';
import type { ScheduleFormData } from '@/components/schedule/VoiceGuidedScheduleForm';
```

### B∆∞·ªõc 2: Thay th·∫ø Dialog Content

**Tr∆∞·ªõc ƒë√¢y:**
```tsx
<DialogContent className="max-w-2xl max-h-[90vh] overflow-y-auto">
  <DialogHeader>...</DialogHeader>
  
  {/* Form c≈© v·ªõi nhi·ªÅu Input, Select, Calendar... */}
  <div className="grid gap-4 py-4">
    {/* ... */}
  </div>
  
  <DialogFooter>
    <Button onClick={handleSubmit}>Th√™m m·ªõi</Button>
  </DialogFooter>
</DialogContent>
```

**Sau khi t√≠ch h·ª£p:**
```tsx
<DialogContent className="max-w-2xl max-h-[90vh] overflow-y-auto">
  <DialogHeader>
    <DialogTitle>
      {editingSchedule ? 'Ch·ªânh s·ª≠a l·ªãch c√¥ng t√°c' : 'Th√™m l·ªãch c√¥ng t√°c m·ªõi'}
    </DialogTitle>
    <DialogDescription>
      ƒêi·ªÅn th√¥ng tin chi ti·∫øt ho·∫∑c s·ª≠ d·ª•ng gi·ªçng n√≥i ƒë·ªÉ nh·∫≠p li·ªáu
    </DialogDescription>
  </DialogHeader>

  <VoiceGuidedScheduleForm
    onSubmit={handleFormSubmit}
    onCancel={() => setIsDialogOpen(false)}
    initialData={editingSchedule ? {
      date: new Date(editingSchedule.date),
      startTime: editingSchedule.startTime,
      endTime: editingSchedule.endTime,
      content: editingSchedule.content,
      location: editingSchedule.location,
      leader: editingSchedule.leader,
      participants: editingSchedule.participants.join(', '),
      preparingUnit: editingSchedule.preparingUnit,
      eventType: editingSchedule.eventType || '',
      notes: editingSchedule.notes || ''
    } : undefined}
  />
</DialogContent>
```

### B∆∞·ªõc 3: C·∫≠p nh·∫≠t handleSubmit

```tsx
const handleFormSubmit = async (data: ScheduleFormData) => {
  const scheduleData = {
    date: data.date,
    dayOfWeek: format(data.date, 'EEEE', { locale: vi }),
    startTime: data.startTime,
    endTime: data.endTime,
    content: data.content,
    location: data.location,
    leader: data.leader,
    participants: data.participants.split(',').map(p => p.trim()).filter(Boolean),
    preparingUnit: data.preparingUnit,
    notes: data.notes,
    eventType: data.eventType as ScheduleEventType,
    status: 'draft' as ScheduleStatus,
    createdBy: user?.id || 'admin',
  };

  try {
    if (editingSchedule) {
      await updateSchedule(editingSchedule.id, scheduleData);
      toast({ title: 'ƒê√£ c·∫≠p nh·∫≠t l·ªãch c√¥ng t√°c' });
    } else {
      await addSchedule(scheduleData);
      toast({ title: 'ƒê√£ th√™m l·ªãch c√¥ng t√°c m·ªõi' });
    }
    setIsDialogOpen(false);
    setEditingSchedule(null);
  } catch (err: any) {
    toast({
      title: 'L·ªói',
      description: err?.message || 'Kh√¥ng th·ªÉ l∆∞u l·ªãch',
      variant: 'destructive'
    });
  }
};
```

## üîß T√≠ch h·ª£p LLM th·ª±c s·ª±

### Option 1: OpenAI GPT

```typescript
// src/services/voiceAI.service.ts

import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true // Ch·ªâ d√πng cho demo, production n√™n g·ªçi qua backend
});

export async function processVoiceInput(
  transcript: string,
  currentField: ScheduleField
): Promise<VoiceProcessingResult> {
  try {
    const fieldMeta = SCHEDULE_FIELDS.find(f => f.name === currentField);
    if (!fieldMeta) {
      return { status: 'DONE', error: 'Invalid field' };
    }

    const userPrompt = `
Tr∆∞·ªùng hi·ªán t·∫°i: ${fieldMeta.name}
Lo·∫°i d·ªØ li·ªáu: ${fieldMeta.type}
${fieldMeta.enumValues ? `Gi√° tr·ªã h·ª£p l·ªá: ${fieldMeta.enumValues.join(', ')}` : ''}

VƒÉn b·∫£n gi·ªçng n√≥i: "${transcript}"

H√£y x·ª≠ l√Ω v√† tr·∫£ v·ªÅ JSON theo ƒë√∫ng format quy ƒë·ªãnh.`;

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: SYSTEM_PROMPT },
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.3,
      response_format: { type: 'json_object' }
    });

    const result = JSON.parse(response.choices[0].message.content || '{}');
    return result as VoiceProcessingResult;

  } catch (error) {
    console.error('[VoiceAI] OpenAI error:', error);
    // Fallback to rule-based
    return fallbackProcessing(transcript, fieldMeta);
  }
}
```

### Option 2: Google Gemini

```typescript
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(import.meta.env.VITE_GEMINI_API_KEY);

export async function processVoiceInput(
  transcript: string,
  currentField: ScheduleField
): Promise<VoiceProcessingResult> {
  try {
    const fieldMeta = SCHEDULE_FIELDS.find(f => f.name === currentField);
    if (!fieldMeta) {
      return { status: 'DONE', error: 'Invalid field' };
    }

    const model = genAI.getGenerativeModel({ 
      model: 'gemini-pro',
      generationConfig: {
        temperature: 0.3,
        responseMimeType: 'application/json'
      }
    });

    const prompt = `${SYSTEM_PROMPT}

Tr∆∞·ªùng hi·ªán t·∫°i: ${fieldMeta.name}
Lo·∫°i d·ªØ li·ªáu: ${fieldMeta.type}
${fieldMeta.enumValues ? `Gi√° tr·ªã h·ª£p l·ªá: ${fieldMeta.enumValues.join(', ')}` : ''}

VƒÉn b·∫£n gi·ªçng n√≥i: "${transcript}"`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    return JSON.parse(text) as VoiceProcessingResult;

  } catch (error) {
    console.error('[VoiceAI] Gemini error:', error);
    return fallbackProcessing(transcript, fieldMeta);
  }
}
```

### Option 3: Backend API (Khuy·∫øn ngh·ªã cho Production)

```typescript
export async function processVoiceInput(
  transcript: string,
  currentField: ScheduleField
): Promise<VoiceProcessingResult> {
  try {
    const response = await fetch('/api/ai/process-voice', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${localStorage.getItem('tbu_auth_token')}`
      },
      body: JSON.stringify({
        transcript,
        field: currentField
      })
    });

    if (!response.ok) {
      throw new Error('API call failed');
    }

    const result = await response.json();
    return result as VoiceProcessingResult;

  } catch (error) {
    console.error('[VoiceAI] API error:', error);
    // Fallback to rule-based
    const fieldMeta = SCHEDULE_FIELDS.find(f => f.name === currentField);
    return fallbackProcessing(transcript, fieldMeta!);
  }
}
```

## üìù Environment Variables

T·∫°o file `.env`:

```env
# OpenAI
VITE_OPENAI_API_KEY=sk-...

# Google Gemini
VITE_GEMINI_API_KEY=...

# Backend API
VITE_API_BASE_URL=http://localhost:3000
```

## üß™ Testing

### 1. Ch·∫°y Demo Page

```bash
# Th√™m route v√†o router
# src/App.tsx ho·∫∑c router config

import VoiceGuidedFormDemo from '@/pages/demo/VoiceGuidedFormDemo';

// Th√™m route
{
  path: '/demo/voice-form',
  element: <VoiceGuidedFormDemo />
}
```

Truy c·∫≠p: `http://localhost:5173/demo/voice-form`

### 2. Test Cases

#### Test Case 1: Nh·∫≠p ƒë·∫ßy ƒë·ªß
- B·∫≠t gi·ªçng n√≥i
- Nh·∫≠p t·∫•t c·∫£ tr∆∞·ªùng theo h∆∞·ªõng d·∫´n
- Ki·ªÉm tra k·∫øt qu·∫£

#### Test Case 2: B·ªè qua tr∆∞·ªùng kh√¥ng b·∫Øt bu·ªôc
- N√≥i "h·∫øt" ƒë·ªÉ b·ªè qua
- Ki·ªÉm tra value = null

#### Test Case 3: S·ª≠a l·ªói
- N√≥i sai ‚Üí kh√¥ng c√≥ "h·∫øt"
- H·ªá th·ªëng ti·∫øp t·ª•c nghe
- N√≥i l·∫°i ƒë√∫ng

## üéØ Roadmap

### Phase 1: ‚úÖ Ho√†n th√†nh
- [x] Voice AI Service v·ªõi system prompt
- [x] Voice-Guided Form component
- [x] Fallback processing rule-based
- [x] UI/UX v·ªõi hi·ªáu ·ª©ng
- [x] Documentation

### Phase 2: üöß ƒêang ph√°t tri·ªÉn
- [ ] T√≠ch h·ª£p LLM th·ª±c s·ª± (OpenAI/Gemini)
- [ ] Backend API cho voice processing
- [ ] C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
- [ ] Th√™m ng√¥n ng·ªØ kh√°c (English)

### Phase 3: üìã K·∫ø ho·∫°ch
- [ ] Voice commands (shortcuts)
- [ ] Offline mode v·ªõi local LLM
- [ ] Multi-language support
- [ ] Voice analytics & insights

## üêõ Known Issues

1. **Web Speech API kh√¥ng ·ªïn ƒë·ªãnh**
   - Gi·∫£i ph√°p: Th√™m retry mechanism
   - Fallback: Cho ph√©p nh·∫≠p b·∫±ng tay

2. **Gi·ªçng ƒë·ªãa ph∆∞∆°ng kh√≥ nh·∫≠n d·∫°ng**
   - Gi·∫£i ph√°p: Train custom model
   - Workaround: H∆∞·ªõng d·∫´n n√≥i r√µ h∆°n

3. **C·∫ßn Internet**
   - Gi·∫£i ph√°p: T√≠ch h·ª£p local speech recognition
   - Workaround: Th√¥ng b√°o ng∆∞·ªùi d√πng

## üìû Support

- **Email**: longtran592005@gmail.com
- **GitHub Issues**: [Link to repo]
- **Documentation**: `/docs/VOICE_GUIDED_FORM.md`

---

**Developed by**: TBU AI Team  
**Version**: 1.0.0  
**Last Updated**: 2026-01-19

"""
RAG Pipeline Orchestrator
ƒêi·ªÅu ph·ªëi to√†n b·ªô pipeline RAG: Embed ‚Üí Retrieve ‚Üí Generate

@author TBU AI Team
"""
from typing import List, Dict, Optional
import logging
import asyncio
import sys
import os

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag_config import TOP_K_RETRIEVAL, SIMILARITY_THRESHOLD, get_connection_string

from .embeddings import embedding_model
from .vector_store import vector_store
from .llm_generator import llm_generator
from .query_cache import query_cache
from .document_loader import (
    format_schedule_for_embedding,
    format_news_for_embedding,
    format_announcement_for_embedding,
    load_info_docx,
    chunk_text
)
from .date_parser import (
    parse_date_expression,
    enhance_query_with_date,
    get_current_date_context,
    get_date_filter_sql,
    format_date_vietnamese
)

logger = logging.getLogger(__name__)


class RAGChain:
    """
    Main RAG Pipeline
    Coordinates embedding, retrieval, and generation
    """
    
    def __init__(self):
        self.embedding = embedding_model
        self.vector_store = vector_store
        self.llm = llm_generator
        self.cache = query_cache
    
    async def query(
        self,
        question: str,
        source_type: str = None,
        chat_history: List[Dict] = None,
        top_k: int = TOP_K_RETRIEVAL,
        threshold: float = SIMILARITY_THRESHOLD
    ) -> Dict:
        """
        Execute RAG pipeline
        
        Args:
            question: User's question
            source_type: Filter by source type (optional)
            chat_history: Conversation history
            top_k: Number of documents to retrieve
            threshold: Minimum similarity threshold
            
        Returns:
            {
                "answer": str,
                "sources": [{"content": str, "metadata": dict, "score": float}],
                "query": str,
                "num_retrieved": int
            }
        """
        logger.info(f"üîç RAG Query: {question[:80]}...")
        
        try:
            # Step 0: Check if this is a greeting/casual chat
            is_greeting = self._is_greeting_or_casual(question)
            if is_greeting:
                logger.info("üëã Detected greeting/casual chat - skipping schedule lookup")
                # Return simple greeting response without RAG
                return self._handle_greeting(question)
            
            # Step 0b: Check cache first (skip for date-specific queries)
            date_info = parse_date_expression(question)
            is_schedule_query = self._is_schedule_query(question)
            
            # Only use cache for non-schedule queries
            if not is_schedule_query:
                cached = self.cache.get(question, source_type)
                if cached:
                    logger.info("‚ö° Returning cached response")
                    return cached
            
            # Step 0c: Parse date from question and enhance query
            # Only enhance with date if actually asking about schedule
            if is_schedule_query:
                enhanced_query = enhance_query_with_date(question)
            else:
                enhanced_query = question
            current_date_ctx = get_current_date_context()
            
            # Step 1: Embed the enhanced query
            logger.debug("Step 1: Embedding query...")
            query_embedding = self.embedding.embed_text(enhanced_query)
            
            # Step 2: Retrieve relevant documents
            logger.debug("Step 2: Retrieving documents...")
            
            # If asking about schedule AND has date, do direct DB query
            extra_schedules = []
            if is_schedule_query and date_info:
                extra_schedules = self._query_schedules_by_date(date_info)
                logger.info(f"üìÖ Found {len(extra_schedules)} schedules for specified date")
            
            # Vector similarity search
            results = self.vector_store.similarity_search(
                query_embedding,
                top_k=top_k,
                source_type=source_type,
                threshold=threshold
            )
            
            logger.info(f"üìö Retrieved {len(results)} relevant documents from vector store")
            
            # Step 3: Prepare context documents
            context_docs = []
            
            # Add extra schedules from direct query (higher priority)
            for schedule in extra_schedules:
                context_docs.append({
                    "content": schedule['content'],
                    "metadata": {"source_type": "schedule", "date": schedule.get('date', '')},
                    "score": 1.0  # Direct match = highest score
                })
            
            # Add vector search results
            for doc_id, content, score, metadata in results:
                # Avoid duplicates
                if not any(d['content'] == content for d in context_docs):
                    context_docs.append({
                        "content": content,
                        "metadata": {**metadata, "doc_id": doc_id},
                        "score": score
                    })
            
            if not context_docs:
                # No relevant documents found
                logger.info("‚ö†Ô∏è No relevant documents found")
                return {
                    "answer": self._get_no_context_response(question),
                    "sources": [],
                    "query": question,
                    "num_retrieved": 0
                }
            
            # Step 4: Generate response using LLM with date context
            logger.debug("Step 4: Generating response...")
            answer = await self.llm.generate(
                query=question,
                context_docs=context_docs,
                chat_history=chat_history,
                extra_context=current_date_ctx
            )
            
            # Prepare sources for response (truncate content for display)
            sources = [
                {
                    "content": d["content"][:300] + "..." if len(d["content"]) > 300 else d["content"],
                    "metadata": d["metadata"],
                    "score": round(d["score"], 3)
                }
                for d in context_docs
            ]
            
            result = {
                "answer": answer,
                "sources": sources,
                "query": question,
                "num_retrieved": len(context_docs)
            }
            
            # Cache the result (only for non-schedule queries)
            if not is_schedule_query:
                self.cache.set(question, result, source_type)
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå RAG query error: {e}")
            return {
                "answer": "Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i sau.",
                "sources": [],
                "query": question,
                "num_retrieved": 0,
                "error": str(e)
            }
    
    def _is_greeting_or_casual(self, question: str) -> bool:
        """Check if question is a greeting or casual chat (not asking for info)"""
        greeting_patterns = [
            'xin ch√†o', 'ch√†o b·∫°n', 'ch√†o', 'hello', 'hi', 'hey',
            'c·∫£m ∆°n', 'thank', 'thanks', 't·∫°m bi·ªát', 'bye',
            'b·∫°n l√† ai', 'b·∫°n t√™n g√¨', 'ai ƒë√≥', 'b·∫°n c√≥ th·ªÉ l√†m g√¨',
            'b·∫°n kh·ªèe', 'kh·ªèe kh√¥ng', '∆°i', '√™', 'n√†y'
        ]
        question_lower = question.lower().strip()
        
        # Short greetings (< 15 chars) are usually casual
        if len(question_lower) < 15 and any(g in question_lower for g in greeting_patterns):
            return True
        
        # Check if ONLY greeting words (no other content)
        for pattern in greeting_patterns:
            if question_lower == pattern or question_lower.startswith(pattern + ' '):
                # Check if there's actual question content after greeting
                remaining = question_lower.replace(pattern, '').strip()
                if len(remaining) < 10:  # Just greeting, no real question
                    return True
        
        return False
    
    def _is_schedule_query(self, question: str) -> bool:
        """Check if question is specifically about schedule/calendar"""
        # Must contain schedule-specific keywords
        schedule_keywords = [
            'l·ªãch', 'l·ªãch c√¥ng t√°c', 'l·ªãch h·ªçp', 'l·ªãch l√†m vi·ªác',
            'cu·ªôc h·ªçp', 'h·ªçp g√¨', 's·ª± ki·ªán', 'ho·∫°t ƒë·ªông g√¨',
            'c√≥ g√¨', 'l√†m g√¨', 'di·ªÖn ra', 't·ªï ch·ª©c'
        ]
        
        # Time-related keywords that indicate asking about schedule
        time_schedule_phrases = [
            'h√¥m nay c√≥', 'ng√†y mai c√≥', 'tu·∫ßn n√†y c√≥', 'tu·∫ßn sau c√≥',
            'h√¥m nay l√†m', 'ng√†y mai l√†m', 'c√≥ l·ªãch', 'c√≥ h·ªçp',
            'l·ªãch g√¨', 'h·ªçp g√¨', 'g√¨ kh√¥ng'
        ]
        
        question_lower = question.lower()
        
        # Check for explicit schedule keywords
        if any(kw in question_lower for kw in schedule_keywords):
            return True
        
        # Check for time + schedule phrases
        if any(phrase in question_lower for phrase in time_schedule_phrases):
            return True
        
        return False
    
    def _handle_greeting(self, question: str) -> dict:
        """
        Handle greeting/casual chat without RAG lookup
        
        Args:
            question: User's greeting message
            
        Returns:
            Response dict with friendly greeting
        """
        question_lower = question.lower().strip()
        
        # Detect type of greeting and respond appropriately
        if any(g in question_lower for g in ['xin ch√†o', 'ch√†o b·∫°n', 'ch√†o', 'hello', 'hi', 'hey']):
            answer = "Xin ch√†o! üëã T√¥i l√† **Tr·ª£ l√Ω ·∫£o TBU**. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n\n" \
                     "üìÖ **Tra c·ª©u l·ªãch c√¥ng t√°c** - H·ªèi: \"H√¥m nay c√≥ l·ªãch g√¨?\"\n" \
                     "üì∞ **Tin t·ª©c & Th√¥ng b√°o** - H·ªèi: \"Tin t·ª©c m·ªõi nh·∫•t\"\n" \
                     "üè´ **Th√¥ng tin tr∆∞·ªùng** - H·ªèi: \"Tr∆∞·ªùng c√≥ nh·ªØng ng√†nh ƒë√†o t·∫°o g√¨?\"\n\n" \
                     "B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ ·∫°?"
        elif any(g in question_lower for g in ['c·∫£m ∆°n', 'thank', 'thanks']):
            answer = "Kh√¥ng c√≥ g√¨ ·∫°! üòä R·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. N·∫øu c·∫ßn th√™m th√¥ng tin g√¨, c·ª© h·ªèi t√¥i nh√©!"
        elif any(g in question_lower for g in ['t·∫°m bi·ªát', 'bye', 'goodbye']):
            answer = "T·∫°m bi·ªát b·∫°n! üëã H·∫πn g·∫∑p l·∫°i. Ch√∫c b·∫°n m·ªôt ng√†y t·ªët l√†nh!"
        elif any(g in question_lower for g in ['b·∫°n l√† ai', 'b·∫°n t√™n g√¨', 'ai ƒë√≥']):
            answer = "T√¥i l√† **Tr·ª£ l√Ω ·∫£o TBU** - chatbot h·ªó tr·ª£ tra c·ª©u th√¥ng tin c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc Th√°i B√¨nh. " \
                     "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n xem l·ªãch c√¥ng t√°c, tin t·ª©c, th√¥ng b√°o v√† c√°c th√¥ng tin v·ªÅ nh√† tr∆∞·ªùng."
        elif any(g in question_lower for g in ['b·∫°n c√≥ th·ªÉ l√†m g√¨', 'gi√∫p g√¨', 'h·ªó tr·ª£ g√¨']):
            answer = "T√¥i c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n:\n\n" \
                     "üìÖ **L·ªãch c√¥ng t√°c**: Tra c·ª©u l·ªãch h·ªçp, s·ª± ki·ªán theo ng√†y\n" \
                     "üì∞ **Tin t·ª©c**: Xem tin t·ª©c m·ªõi nh·∫•t c·ªßa tr∆∞·ªùng\n" \
                     "üì¢ **Th√¥ng b√°o**: Xem c√°c th√¥ng b√°o quan tr·ªçng\n" \
                     "üè´ **Th√¥ng tin tr∆∞·ªùng**: Ng√†nh ƒë√†o t·∫°o, tuy·ªÉn sinh, li√™n h·ªá...\n\n" \
                     "H√£y ƒë·∫∑t c√¢u h·ªèi, t√¥i s·∫Ω c·ªë g·∫Øng tr·∫£ l·ªùi t·ªët nh·∫•t!"
        else:
            answer = "Xin ch√†o! T√¥i l√† Tr·ª£ l√Ω ·∫£o TBU. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ ·∫°?"
        
        return {
            "answer": answer,
            "sources": [],
            "query": question,
            "num_retrieved": 0
        }
    
    def _query_schedules_by_date(self, date_info: dict) -> List[Dict]:
        """
        Query schedules directly from database by date
        
        Args:
            date_info: Parsed date information
            
        Returns:
            List of schedule dictionaries
        """
        import pyodbc
        
        try:
            where_clause, params = get_date_filter_sql(date_info)
            if not where_clause:
                return []
            
            conn = pyodbc.connect(get_connection_string())
            cursor = conn.cursor()
            
            query = f"""
                SELECT id, date, day_of_week, start_time, end_time,
                       content, location, leader, participants,
                       preparing_unit, cooperating_units, notes
                FROM schedules
                WHERE status IN ('approved', 'draft') AND {where_clause}
                ORDER BY date, start_time
            """
            
            cursor.execute(query, params)
            columns = [col[0] for col in cursor.description]
            rows = cursor.fetchall()
            conn.close()
            
            schedules = []
            for row in rows:
                schedule_dict = dict(zip(columns, row))
                # Format schedule for display
                formatted = format_schedule_for_embedding(schedule_dict)
                logger.info(f"üìã Schedule formatted content: {formatted[:200]}...")
                schedules.append({
                    'content': formatted,
                    'date': str(schedule_dict.get('date', ''))
                })
            
            return schedules
            
        except Exception as e:
            logger.error(f"‚ùå Error querying schedules by date: {e}")
            return []
    
    def _get_no_context_response(self, question: str) -> str:
        """Generate response when no context is found"""
        # Check if it's a greeting
        greetings = ['xin ch√†o', 'ch√†o', 'hello', 'hi', 'hey']
        if any(g in question.lower() for g in greetings):
            return """Xin ch√†o! üëã

T√¥i l√† **Tr·ª£ l√Ω ·∫£o TBU** - h·ªá th·ªëng h·ªó tr·ª£ tra c·ª©u th√¥ng tin cho Tr∆∞·ªùng ƒê·∫°i h·ªçc Th√°i B√¨nh.

T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:
‚Ä¢ üìÖ Tra c·ª©u l·ªãch c√¥ng t√°c
‚Ä¢ üì∞ Xem tin t·ª©c, th√¥ng b√°o
‚Ä¢ üè´ T√¨m hi·ªÉu th√¥ng tin v·ªÅ tr∆∞·ªùng

H√£y ƒë·∫∑t c√¢u h·ªèi ƒë·ªÉ b·∫Øt ƒë·∫ßu!"""
        
        # Check if asking for help
        help_keywords = ['gi√∫p', 'tr·ª£ gi√∫p', 'help', 'h∆∞·ªõng d·∫´n', 'l√†m g√¨']
        if any(k in question.lower() for k in help_keywords):
            return """üìã **H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Tr·ª£ l√Ω TBU**

B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ:

**L·ªãch c√¥ng t√°c:**
‚Ä¢ "L·ªãch c√¥ng t√°c h√¥m nay"
‚Ä¢ "L·ªãch tu·∫ßn n√†y"
‚Ä¢ "L·ªãch c·ªßa Hi·ªáu tr∆∞·ªüng"
‚Ä¢ "Ng√†y mai c√≥ h·ªçp g√¨?"

**Tin t·ª©c & Th√¥ng b√°o:**
‚Ä¢ "Tin t·ª©c m·ªõi nh·∫•t"
‚Ä¢ "Th√¥ng b√°o quan tr·ªçng"

**Th√¥ng tin tr∆∞·ªùng:**
‚Ä¢ "Gi·ªõi thi·ªáu v·ªÅ tr∆∞·ªùng"
‚Ä¢ "ƒê·ªãa ch·ªâ li√™n h·ªá"

H√£y ƒë·∫∑t c√¢u h·ªèi c·ª• th·ªÉ ƒë·ªÉ t√¥i c√≥ th·ªÉ h·ªó tr·ª£ t·ªët nh·∫•t!"""
        
        # Default no context response
        return """Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa b·∫°n.

B·∫°n c√≥ th·ªÉ th·ª≠:
‚Ä¢ H·ªèi c·ª• th·ªÉ h∆°n (VD: "L·ªãch c√¥ng t√°c ng√†y 22/01/2026")
‚Ä¢ H·ªèi v·ªÅ l·ªãch c√¥ng t√°c, tin t·ª©c, ho·∫∑c th√¥ng tin tr∆∞·ªùng

N·∫øu c·∫ßn h·ªó tr·ª£ th√™m, h√£y g√µ "gi√∫p ƒë·ª°" ƒë·ªÉ xem h∆∞·ªõng d·∫´n."""
    
    async def index_schedules(self, schedules: List[Dict]) -> int:
        """
        Index schedules into vector store
        
        Args:
            schedules: List of schedule dictionaries
            
        Returns:
            Number of indexed documents
        """
        if not schedules:
            logger.warning("‚ö†Ô∏è No schedules to index")
            return 0
        
        logger.info(f"üìä Indexing {len(schedules)} schedules...")
        
        # Delete old schedule embeddings first
        self.vector_store.delete_by_source("schedule")
        
        texts = []
        source_ids = []
        metadatas = []
        
        for schedule in schedules:
            # Format schedule for embedding
            text = format_schedule_for_embedding(schedule)
            texts.append(text)
            
            source_ids.append(str(schedule.get('id', '')))
            
            metadatas.append({
                "date": str(schedule.get('date', '')),
                "leader": schedule.get('leader', ''),
                "location": schedule.get('location', ''),
                "content_preview": schedule.get('content', '')[:100]
            })
        
        # Generate embeddings
        logger.info("Generating embeddings...")
        embeddings = self.embedding.embed_texts(texts)
        
        # Store in vector database
        logger.info("Storing in vector database...")
        self.vector_store.add_documents(
            texts=texts,
            embeddings=embeddings,
            source_type="schedule",
            source_ids=source_ids,
            metadatas=metadatas
        )
        
        logger.info(f"‚úÖ Indexed {len(texts)} schedules successfully")
        return len(texts)
    
    async def index_news(self, news_list: List[Dict]) -> int:
        """
        Index news into vector store
        
        Args:
            news_list: List of news dictionaries
            
        Returns:
            Number of indexed documents
        """
        if not news_list:
            return 0
        
        logger.info(f"üì∞ Indexing {len(news_list)} news articles...")
        
        self.vector_store.delete_by_source("news")
        
        texts = []
        source_ids = []
        metadatas = []
        
        for news in news_list:
            text = format_news_for_embedding(news)
            
            # Chunk if too long
            chunks = chunk_text(text)
            
            for i, chunk in enumerate(chunks):
                texts.append(chunk)
                source_ids.append(f"{news.get('id', '')}_{i}")
                metadatas.append({
                    "title": news.get('title', ''),
                    "category": news.get('category', ''),
                    "chunk_index": i
                })
        
        if texts:
            embeddings = self.embedding.embed_texts(texts)
            self.vector_store.add_documents(
                texts=texts,
                embeddings=embeddings,
                source_type="news",
                source_ids=source_ids,
                metadatas=metadatas
            )
        
        logger.info(f"‚úÖ Indexed {len(texts)} news chunks")
        return len(texts)
    
    async def index_announcements(self, announcements: List[Dict]) -> int:
        """
        Index announcements into vector store
        
        Args:
            announcements: List of announcement dictionaries
            
        Returns:
            Number of indexed documents
        """
        if not announcements:
            return 0
        
        logger.info(f"üì¢ Indexing {len(announcements)} announcements...")
        
        self.vector_store.delete_by_source("announcement")
        
        texts = []
        source_ids = []
        metadatas = []
        
        for ann in announcements:
            text = format_announcement_for_embedding(ann)
            chunks = chunk_text(text)
            
            for i, chunk in enumerate(chunks):
                texts.append(chunk)
                source_ids.append(f"{ann.get('id', '')}_{i}")
                metadatas.append({
                    "title": ann.get('title', ''),
                    "priority": ann.get('priority', ''),
                    "chunk_index": i
                })
        
        if texts:
            embeddings = self.embedding.embed_texts(texts)
            self.vector_store.add_documents(
                texts=texts,
                embeddings=embeddings,
                source_type="announcement",
                source_ids=source_ids,
                metadatas=metadatas
            )
        
        logger.info(f"‚úÖ Indexed {len(texts)} announcement chunks")
        return len(texts)
    
    async def index_document(self) -> int:
        """
        Index info.docx into vector store
        
        Returns:
            Number of indexed chunks
        """
        logger.info("üìÑ Indexing info.docx...")
        
        # Delete old document embeddings
        self.vector_store.delete_by_source("document")
        
        # Load and chunk document
        docs = load_info_docx()
        
        if not docs:
            logger.warning("‚ö†Ô∏è No content from info.docx")
            return 0
        
        texts = [d['content'] for d in docs]
        metadatas = [d['metadata'] for d in docs]
        
        # Generate embeddings
        embeddings = self.embedding.embed_texts(texts)
        
        # Store
        self.vector_store.add_documents(
            texts=texts,
            embeddings=embeddings,
            source_type="document",
            metadatas=metadatas
        )
        
        logger.info(f"‚úÖ Indexed {len(texts)} document chunks")
        return len(texts)
    
    async def reindex_all_from_db(self) -> Dict:
        """
        Reindex all data from database
        
        Returns:
            Dict with counts of indexed items
        """
        import pyodbc
        
        logger.info("üîÑ Starting full reindex from database...")
        
        conn = pyodbc.connect(get_connection_string())
        cursor = conn.cursor()
        
        results = {}
        
        # Index schedules (approved ho·∫∑c draft ƒë·ªÉ test)
        cursor.execute("""
            SELECT id, date, day_of_week, start_time, end_time, 
                   content, location, leader, participants, 
                   preparing_unit, cooperating_units, notes
            FROM schedules 
            WHERE status IN ('approved', 'draft')
        """)
        
        columns = [col[0] for col in cursor.description]
        schedules = [dict(zip(columns, row)) for row in cursor.fetchall()]
        results['schedules'] = await self.index_schedules(schedules)
        
        # Index news
        cursor.execute("""
            SELECT id, title, summary, content, category, published_at
            FROM news
        """)
        
        columns = [col[0] for col in cursor.description]
        news_list = [dict(zip(columns, row)) for row in cursor.fetchall()]
        results['news'] = await self.index_news(news_list)
        
        # Index announcements
        cursor.execute("""
            SELECT id, title, content, priority, published_at
            FROM announcements
            WHERE expires_at IS NULL OR expires_at > GETDATE()
        """)
        
        columns = [col[0] for col in cursor.description]
        announcements = [dict(zip(columns, row)) for row in cursor.fetchall()]
        results['announcements'] = await self.index_announcements(announcements)
        
        # Index info.docx
        results['document'] = await self.index_document()
        
        conn.close()
        
        logger.info(f"‚úÖ Full reindex complete: {results}")
        return results
    
    async def reindex_schedules_from_db(self) -> int:
        """Reindex only schedules from database"""
        import pyodbc
        
        logger.info("üîÑ Reindexing schedules from database...")
        
        conn = pyodbc.connect(get_connection_string())
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, date, day_of_week, start_time, end_time, 
                   content, location, leader, participants, 
                   preparing_unit, cooperating_units, notes
            FROM schedules 
            WHERE status IN ('approved', 'draft')
        """)
        
        columns = [col[0] for col in cursor.description]
        schedules = [dict(zip(columns, row)) for row in cursor.fetchall()]
        conn.close()
        
        count = await self.index_schedules(schedules)
        logger.info(f"‚úÖ Reindexed {count} schedules")
        return count
    
    async def reindex_news_from_db(self) -> int:
        """Reindex only news from database"""
        import pyodbc
        
        logger.info("üîÑ Reindexing news from database...")
        
        conn = pyodbc.connect(get_connection_string())
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, title, summary, content, category, published_at
            FROM news
        """)
        
        columns = [col[0] for col in cursor.description]
        news_list = [dict(zip(columns, row)) for row in cursor.fetchall()]
        conn.close()
        
        count = await self.index_news(news_list)
        logger.info(f"‚úÖ Reindexed {count} news")
        return count
    
    async def reindex_announcements_from_db(self) -> int:
        """Reindex only announcements from database"""
        import pyodbc
        
        logger.info("üîÑ Reindexing announcements from database...")
        
        conn = pyodbc.connect(get_connection_string())
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, title, content, priority, published_at
            FROM announcements
            WHERE expires_at IS NULL OR expires_at > GETDATE()
        """)
        
        columns = [col[0] for col in cursor.description]
        announcements = [dict(zip(columns, row)) for row in cursor.fetchall()]
        conn.close()
        
        count = await self.index_announcements(announcements)
        logger.info(f"‚úÖ Reindexed {count} announcements")
        return count
    
    def get_stats(self) -> Dict:
        """Get vector store statistics"""
        return self.vector_store.get_stats()


# Singleton instance
rag_chain = RAGChain()


# Test function
async def test_rag_chain():
    """Test RAG chain functionality"""
    print("Testing RAG Chain...")
    
    chain = RAGChain()
    
    # Check LLM health first
    is_healthy = await chain.llm.check_health()
    print(f"LLM Health: {is_healthy}")
    
    if not is_healthy:
        print("‚ùå Please start Ollama first")
        return
    
    # Test query (will use whatever is in vector store)
    print("\n--- Testing Query ---")
    result = await chain.query("Xin ch√†o")
    print(f"Answer: {result['answer'][:200]}...")
    print(f"Sources: {len(result['sources'])}")
    
    # Get stats
    print("\n--- Vector Store Stats ---")
    stats = chain.get_stats()
    print(f"Stats: {stats}")
    
    await chain.llm.close()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(test_rag_chain())

import argparse
import os
import time
import torch
import whisper

# Model Whisper ti·∫øng Vi·ªát
DEFAULT_MODEL = "large-v3"

# Prompt ti·∫øng Vi·ªát gi√∫p model ƒë·ªãnh h√¨nh c√°ch vi·∫øt hoa v√† ng·∫Øt c√¢u
VIETNAMESE_PROMPT = "Xin ch√†o c√°c b·∫°n. ƒê√¢y l√† b·∫£n ghi ch√©p ch√≠nh x√°c, c√≥ ƒë·∫ßy ƒë·ªß d·∫•u ch·∫•m, d·∫•u ph·∫©y. T√™n ri√™ng nh∆∞ H√† N·ªôi, H·ªì Ch√≠ Minh, VinAI ƒë·ªÅu ƒë∆∞·ª£c vi·∫øt hoa chu·∫©n x√°c."

def check_cuda_available():
    """Ki·ªÉm tra CUDA c√≥ s·∫µn kh√¥ng"""
    if torch.cuda.is_available():
        device_count = torch.cuda.device_count()
        device_name = torch.cuda.get_device_name(0)
        print(f"--- üéÆ CUDA Available: {device_count} device(s) ---")
        print(f"--- üéÆ GPU: {device_name} ---")
        return True
    else:
        print("--- ‚ö†Ô∏è CUDA NOT Available - Will use CPU ---")
        return False

def main():
    parser = argparse.ArgumentParser(description="Vietnamese Speech-to-Text (Whisper)")
    parser.add_argument("input_file", help="Path to audio file")
    parser.add_argument("-o", "--output", help="Output file path (default: stdout)")
    parser.add_argument("--model", default=DEFAULT_MODEL, help=f"Whisper model (default: {DEFAULT_MODEL})")
    parser.add_argument("--device", default="cuda", help="Device: cuda or cpu (default: cuda)")
    parser.add_argument("--beam_size", type=int, default=5, help="Beam size for decoding (default: 5)")
    
    args = parser.parse_args()

    if not os.path.exists(args.input_file):
        print(f"‚ùå File not found: {args.input_file}")
        return

    # Ki·ªÉm tra GPU
    if args.device == "cuda":
        if not check_cuda_available():
            print("--- ‚ö†Ô∏è Falling back to CPU ---")
            args.device = "cpu"

    print(f"--- üöÄ Loading Model: {args.model} on {args.device.upper()} ---")
    
    try:
        model = whisper.load_model(args.model, device=args.device)
        print(f"--- ‚úÖ Model loaded successfully on {args.device.upper()} ---")
    except Exception as e:
        print(f"--- ‚ùå Failed to load model: {e} ---")
        return

    print(f"--- ‚ö° Processing: {args.input_file} ---")
    start_time = time.time()
    
    # Transcribe v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u cho ti·∫øng Vi·ªát
    result = model.transcribe(
        args.input_file,
        language="vi",
        initial_prompt=VIETNAMESE_PROMPT,
        beam_size=args.beam_size
    )

    text = result["text"].strip()
    processing_time = time.time() - start_time

    # Output
    if args.output:
        with open(args.output, "w", encoding="utf-8") as f:
            f.write(text)
        print(f"\n--- ‚úÖ Done! Saved to: {args.output} ---")
    else:
        print("\n--- ‚úÖ Result: ---")
        print(text)
    
    print(f"\n‚è±Ô∏è  Processing time: {processing_time:.1f}s")

if __name__ == "__main__":
    main()
